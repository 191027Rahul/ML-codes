{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81f33b96-5699-4749-a947-ec0f6f375ed5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'strain_rate_per_grid.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m max_magnitude \u001b[38;5;241m=\u001b[39m max_magnitude_data\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Load strain rate data\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m strain_rate_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(file_paths[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrain_rate_per_grid\u001b[39m\u001b[38;5;124m'\u001b[39m], header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, usecols\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:Z\u001b[39m\u001b[38;5;124m'\u001b[39m, skiprows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m36\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Load specified sheets from earthquake_grid_seismic_parameters.xlsx\u001b[39;00m\n\u001b[0;32m     42\u001b[0m sheet_mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb_values\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# Sheet 2\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprobability_of_Magnitude_6\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Sheet 4\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseismic_rate_change\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m7\u001b[39m  \u001b[38;5;66;03m# Sheet 8\u001b[39;00m\n\u001b[0;32m     48\u001b[0m }\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:504\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    503\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(\n\u001b[0;32m    505\u001b[0m         io,\n\u001b[0;32m    506\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    507\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    508\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m    509\u001b[0m     )\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1563\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1563\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[0;32m   1564\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[0;32m   1565\u001b[0m     )\n\u001b[0;32m   1566\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1567\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1568\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1570\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1419\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1417\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1419\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m   1420\u001b[0m     content_or_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1421\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1422\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1423\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    873\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'strain_rate_per_grid.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define file paths for each parameter\n",
    "file_paths = {\n",
    "    'time_since_last_eq': 'time_since_last_earthquake_Mw4_years.xlsx',\n",
    "    'seismic_energy': 'seismic_energy_per_grid_with_neighbors.xlsx',\n",
    "    'earthquake_grid_data_with_distances': 'earthquake_grid_data_with_distances.xlsx',\n",
    "    'fault_density': 'fault_density_per_km2.xlsx',\n",
    "    'earthquake_density_grid': 'earthquake_density_grid.xlsx',\n",
    "    'earthquake_mean_magnitudes_and_b_values_grid_data': 'earthquake_mean_magnitudes_and_b_values_grid_data.xlsx',\n",
    "    'earthquake_max_magnitude_grid_data': 'earthquake_max_magnitude_grid_data.xlsx',\n",
    "    'earthquake_grid_seismic_parameters': 'earthquake_grid_seismic_parameters.xlsx',\n",
    "    'strain_rate_per_grid': 'strain_rate_per_grid.xlsx',\n",
    "    'earthquake_years_grid_data': 'earthquake_years_grid_data.xlsx',\n",
    "    'avg_time_between_eq_Mw5_years': 'avg_time_between_eq_Mw5_years.xlsx'  # New file\n",
    "}\n",
    "\n",
    "# Load each dataset, select the grid data, and flatten it\n",
    "time_since_last_eq = pd.read_excel(file_paths['time_since_last_eq'], header=None, usecols='C:Z', skiprows=2, nrows=36).values.flatten()\n",
    "seismic_energy = pd.read_excel(file_paths['seismic_energy'], header=None, usecols='C:Z', skiprows=2, nrows=36).values.flatten()\n",
    "\n",
    "# Load data from Sheet 2 of earthquake_grid_data_with_distances.xlsx\n",
    "earthquake_grid_data = pd.read_excel(file_paths['earthquake_grid_data_with_distances'], sheet_name=1, header=None, usecols='C:Z', skiprows=2, nrows=36)\n",
    "nearest_fault_distances = earthquake_grid_data.values.flatten()\n",
    "\n",
    "fault_density = pd.read_excel(file_paths['fault_density'], header=None, usecols='C:Z', skiprows=2, nrows=36).values.flatten()\n",
    "earthquake_density = pd.read_excel(file_paths['earthquake_density_grid'], header=None, usecols='C:Z', skiprows=2, nrows=36).values.flatten()\n",
    "\n",
    "# Load mean magnitudes data from Sheet 1 of earthquake_mean_magnitudes_and_b_values_grid_data.xlsx\n",
    "mean_magnitude_data = pd.read_excel(file_paths['earthquake_mean_magnitudes_and_b_values_grid_data'], sheet_name=0, header=None, usecols='C:Z', skiprows=2, nrows=36)\n",
    "mean_magnitude = mean_magnitude_data.values.flatten()\n",
    "\n",
    "# Load max magnitude data from earthquake_max_magnitude_grid_data.xlsx\n",
    "max_magnitude_data = pd.read_excel(file_paths['earthquake_max_magnitude_grid_data'], header=None, usecols='C:Z', skiprows=2, nrows=36)\n",
    "max_magnitude = max_magnitude_data.values.flatten()\n",
    "\n",
    "# Load strain rate data\n",
    "strain_rate_data = pd.read_excel(file_paths['strain_rate_per_grid'], header=None, usecols='C:Z', skiprows=2, nrows=36).values.flatten()\n",
    "\n",
    "# Load specified sheets from earthquake_grid_seismic_parameters.xlsx\n",
    "sheet_mapping = {\n",
    "    'b_values': 1,  # Sheet 2\n",
    "    'probability_of_Magnitude_6': 3,  # Sheet 4\n",
    "    'deviation_from_Gutenberg_law': 4,  # Sheet 5\n",
    "    'SD_of_B_value': 5,  # Sheet 6\n",
    "    'seismic_rate_change': 7  # Sheet 8\n",
    "}\n",
    "\n",
    "seismic_param_data = {}\n",
    "for param_name, sheet_index in sheet_mapping.items():\n",
    "    seismic_param_data[param_name] = pd.read_excel(file_paths['earthquake_grid_seismic_parameters'], \n",
    "                                                   sheet_name=sheet_index, header=None, usecols='C:Z', \n",
    "                                                   skiprows=2, nrows=36).values.flatten()\n",
    "\n",
    "# Load earthquake years grid data\n",
    "earthquake_years_data = pd.read_excel(file_paths['earthquake_years_grid_data'], header=None, usecols='C:Z', skiprows=2, nrows=36).values.flatten()\n",
    "\n",
    "# Load average time between earthquakes Mw ≥ 5\n",
    "avg_time_between_eq_Mw5_years = pd.read_excel(file_paths['avg_time_between_eq_Mw5_years'], header=None, usecols='C:Z', skiprows=2, nrows=36).values.flatten()\n",
    "\n",
    "# Ensure all arrays have the same length\n",
    "min_length = min(\n",
    "    len(time_since_last_eq), len(seismic_energy), len(nearest_fault_distances),\n",
    "    len(fault_density), len(earthquake_density), len(mean_magnitude), len(max_magnitude),\n",
    "    len(strain_rate_data), len(earthquake_years_data), len(avg_time_between_eq_Mw5_years),\n",
    "    *(len(data) for data in seismic_param_data.values())\n",
    ")\n",
    "\n",
    "# Truncate all arrays to the minimum length\n",
    "time_since_last_eq = time_since_last_eq[:min_length]\n",
    "seismic_energy = seismic_energy[:min_length]\n",
    "nearest_fault_distances = nearest_fault_distances[:min_length]\n",
    "fault_density = fault_density[:min_length]\n",
    "earthquake_density = earthquake_density[:min_length]\n",
    "mean_magnitude = mean_magnitude[:min_length]\n",
    "max_magnitude = max_magnitude[:min_length]\n",
    "strain_rate_data = strain_rate_data[:min_length]\n",
    "earthquake_years_data = earthquake_years_data[:min_length]\n",
    "avg_time_between_eq_Mw5_years = avg_time_between_eq_Mw5_years[:min_length]\n",
    "\n",
    "for key in seismic_param_data:\n",
    "    seismic_param_data[key] = seismic_param_data[key][:min_length]\n",
    "\n",
    "# Combine the data into a DataFrame\n",
    "combined_data = pd.DataFrame({\n",
    "    'time_since_last_eq': time_since_last_eq,\n",
    "    'seismic_energy': seismic_energy,\n",
    "    'nearest_fault_distances': nearest_fault_distances,\n",
    "    'fault_density': fault_density,\n",
    "    'earthquake_density': earthquake_density,\n",
    "    'mean_magnitude': mean_magnitude,\n",
    "    'max_magnitude': max_magnitude,\n",
    "    'strain_rate': strain_rate_data,\n",
    "    'earthquake_years': earthquake_years_data,\n",
    "    'avg_time_between_eq_Mw5_years': avg_time_between_eq_Mw5_years,  # Include new data\n",
    "    **seismic_param_data\n",
    "})\n",
    "\n",
    "# Replace inf or NaN values with None (which saves as empty cells in Excel)\n",
    "combined_data = combined_data.replace([np.inf, -np.inf, np.nan], None)\n",
    "\n",
    "# Save the updated combined data to an Excel file\n",
    "output_file = 'combined_seismic_data_with_avg_time.xlsx'\n",
    "combined_data.to_excel(output_file, index=False)\n",
    "\n",
    "print(f'Data with all parameters, including average time between earthquakes Mw ≥ 5, has been saved to {output_file}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd31e050-d277-474e-9aeb-f62e63590115",
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquake_grid_data = pd.read_excel(file_paths['earthquake_grid_data_with_distances'], sheet_name=1, header=None, usecols='C:Z', skiprows=2, nrows=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8267b69c-d0de-4479-90ab-ba948fbde768",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((time_since_last_eq.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcf78ce-805c-4ad4-8940-ba10c691620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(earthquake_grid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b89c52-1902-489a-b006-a888c5913923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define file paths\n",
    "file_path = 'seismic_energy_per_grid_with_neighbors.xlsx'  # Example file to extract lat/long\n",
    "#output_file = 'combined_seismic_data_with_lat_lon.xlsx'  # Output file name\n",
    "\n",
    "# Load the strain rate file to get latitude and longitude\n",
    "strain_rate_excel = pd.ExcelFile(file_path)\n",
    "\n",
    "# Extract latitude and longitude data\n",
    "latitude_data = pd.read_excel(strain_rate_excel, header=None, usecols='A', skiprows=2, nrows=36).squeeze().values\n",
    "longitude_data = pd.read_excel(strain_rate_excel, header=None, usecols='C:Z', nrows=1).squeeze().values\n",
    "\n",
    "# Ensure latitude and longitude arrays match the size of the grid\n",
    "latitude_data = latitude_data[:36]  # Assuming 36 rows for latitude\n",
    "longitude_data = longitude_data[:len(longitude_data)]  # Match longitude range\n",
    "\n",
    "# Load the combined dataset\n",
    "combined_data = pd.read_excel(output_file)\n",
    "\n",
    "# Flatten latitude and longitude to match the grid structure\n",
    "latitude_flattened = np.repeat(latitude_data, len(longitude_data))\n",
    "longitude_flattened = np.tile(longitude_data, len(latitude_data))\n",
    "\n",
    "# Add Latitude and Longitude to the combined dataset\n",
    "combined_data['Latitude'] = latitude_flattened[:len(combined_data)]\n",
    "combined_data['Longitude'] = longitude_flattened[:len(combined_data)]\n",
    "\n",
    "# Save the updated combined data to the same Excel file\n",
    "combined_data.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"Updated data with latitude and longitude has been saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b657d-4028-4301-8b44-ff4f1a9ec337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset (assuming it's available and cleaned as before)\n",
    "# data = pd.read_excel('/mnt/data/combined_seismic_data_with_strain_rate.xlsx')\n",
    "columns = ['earthquake_density', 'max_magnitudes', 'min_distances', \n",
    "           'nearest_fault_distances', 'time_since_last_eq', 'strain_rate', \n",
    "           'seismic_energy', 'earthquake_time']  # Including earthquake_time\n",
    "\n",
    "data_clean = data[columns].dropna()\n",
    "\n",
    "# Convert 'earthquake_time' into year ranges\n",
    "data_clean['earthquake_years'] = data_clean['earthquake_time'].apply(\n",
    "    lambda x: sorted([int(year) for year in str(x).split(',')])\n",
    ")\n",
    "\n",
    "# Function to create sliding windows\n",
    "def create_sliding_windows(data, look_back=10, forecast_horizon=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back - forecast_horizon):\n",
    "        # Input: past 10 years data\n",
    "        X.append(data[i:i+look_back])\n",
    "        # Output: forecast next 5 years\n",
    "        y.append(data[i+look_back:i+look_back+forecast_horizon])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create sliding windows\n",
    "look_back_years = 10\n",
    "forecast_years = 5\n",
    "\n",
    "# Select features and create sliding windows\n",
    "X, y = create_sliding_windows(\n",
    "    data_clean[['seismic_energy', 'earthquake_density', 'strain_rate']].values, \n",
    "    look_back_years, \n",
    "    forecast_years\n",
    ")\n",
    "\n",
    "# Ensure the dataset is not empty\n",
    "if len(X) == 0 or len(y) == 0:\n",
    "    raise ValueError(\"The sliding windows created an empty dataset. Please check the data range and look-back settings.\")\n",
    "\n",
    "# Flatten the output (GPR requires scalar outputs per sample, so we train for one year at a time)\n",
    "y = y[:, 0]  # Predicting only the first year in the forecast horizon\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Normalize the data\n",
    "scaler_X = MinMaxScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).ravel()\n",
    "\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2))\n",
    "\n",
    "# Create the Gaussian Process Regressor model\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=1e-10)\n",
    "\n",
    "# Train the GPR model\n",
    "gpr.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_scaled, y_pred_std = gpr.predict(X_test_scaled, return_std=True)\n",
    "\n",
    "# Inverse transform the predictions and standard deviations\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "y_pred_std_original = y_pred_std * (scaler_y.data_range_[0])  # Rescale standard deviation\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R² Score:\", r2)\n",
    "\n",
    "# Plot predictions with uncertainty\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(y_test)), y_test, label='True Values', marker='o', linestyle='--')\n",
    "plt.plot(range(len(y_pred)), y_pred, label='Predicted Values', marker='x', linestyle='-')\n",
    "plt.fill_between(range(len(y_pred)), \n",
    "                 y_pred - 2 * y_pred_std_original, \n",
    "                 y_pred + 2 * y_pred_std_original, \n",
    "                 color='lightblue', alpha=0.5, label='Confidence Interval (95%)')\n",
    "plt.title('GPR Predictions with Uncertainty')\n",
    "plt.xlabel('Test Sample Index')\n",
    "plt.ylabel('Seismic Energy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
